# ğŸ¤– IntegraciÃ³n del Sistema de IA con UniversIA

## ğŸ“‹ Tabla de Contenidos
1. [Arquitectura General](#arquitectura-general)
2. [Proyecto Python (Servicio IA)](#proyecto-python-servicio-ia)
3. [API Next.js (Backend)](#api-nextjs-backend)
4. [Flujo de Datos Completo](#flujo-de-datos-completo)
5. [Deployment](#deployment)

---

## ğŸ—ï¸ Arquitectura General

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FRONTEND (Next.js 15)                          â”‚
â”‚              /app/estudiante/curso/[id]/page.tsx                  â”‚
â”‚                                                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚  Chat Component                                         â”‚      â”‚
â”‚  â”‚  - EnvÃ­a mensaje del estudiante                         â”‚      â”‚
â”‚  â”‚  - Recibe respuesta de la IA                            â”‚      â”‚
â”‚  â”‚  - Muestra historial                                    â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚ fetch/WebSocket
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              BACKEND API (Next.js API Routes)                     â”‚
â”‚                    /api/chat/send.ts                              â”‚
â”‚                    /api/chat/session.ts                           â”‚
â”‚                                                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚  1. Valida autenticaciÃ³n (JWT)                          â”‚      â”‚
â”‚  â”‚  2. Obtiene contexto del estudiante (PostgreSQL)        â”‚      â”‚
â”‚  â”‚  3. Prepara prompt con contexto                         â”‚      â”‚
â”‚  â”‚  4. Llama al Servicio IA Python                         â”‚      â”‚
â”‚  â”‚  5. Guarda mensajes (MongoDB)                           â”‚      â”‚
â”‚  â”‚  6. Actualiza mÃ©tricas (PostgreSQL)                     â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚ HTTP REST API
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              SERVICIO IA (Python - FastAPI)                       â”‚
â”‚                  http://localhost:8000                            â”‚
â”‚                                                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚  Endpoints:                                             â”‚      â”‚
â”‚  â”‚  - POST /api/v1/chat/completions                       â”‚      â”‚
â”‚  â”‚  - POST /api/v1/chat/stream                            â”‚      â”‚
â”‚  â”‚  - GET  /api/v1/chat/health                            â”‚      â”‚
â”‚  â”‚                                                         â”‚      â”‚
â”‚  â”‚  Funcionalidades:                                      â”‚      â”‚
â”‚  â”‚  - LangChain para manejo de contexto                   â”‚      â”‚
â”‚  â”‚  - RAG con embeddings del curso                        â”‚      â”‚
â”‚  â”‚  - IntegraciÃ³n GPT-4/Gemini/Claude                     â”‚      â”‚
â”‚  â”‚  - Sistema de prompts dinÃ¡micos                        â”‚      â”‚
â”‚  â”‚  - EvaluaciÃ³n segÃºn rÃºbricas                           â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â–¼              â–¼              â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚  PostgreSQL  â”‚ â”‚ MongoDB  â”‚ â”‚ OpenAI API â”‚
     â”‚              â”‚ â”‚          â”‚ â”‚ Gemini API â”‚
     â”‚ - Contexto   â”‚ â”‚ - Chats  â”‚ â”‚ Claude API â”‚
     â”‚ - Progreso   â”‚ â”‚ - Logs   â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚ - RÃºbricas   â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ Proyecto Python (Servicio IA)

### **Estructura del Proyecto Python**

```
universia-ia-service/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                    # FastAPI app
â”‚   â”œâ”€â”€ config.py                  # ConfiguraciÃ³n
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ chat_models.py         # Pydantic models
â”‚   â”‚   â””â”€â”€ context_models.py
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ chat_service.py        # LÃ³gica principal del chat
â”‚   â”‚   â”œâ”€â”€ prompt_builder.py      # ConstrucciÃ³n de prompts
â”‚   â”‚   â”œâ”€â”€ rag_service.py         # Retrieval Augmented Generation
â”‚   â”‚   â””â”€â”€ llm_service.py         # IntegraciÃ³n con OpenAI/Gemini
â”‚   â”œâ”€â”€ routers/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ chat_router.py         # Endpoints API
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ db_utils.py            # Helpers de BD
â”‚       â””â”€â”€ logger.py
â”œâ”€â”€ tests/
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â””â”€â”€ README.md
```

### **CÃ³digo Base del Servicio Python**

#### **1. `requirements.txt`**
```txt
fastapi==0.109.0
uvicorn[standard]==0.27.0
pydantic==2.5.0
pydantic-settings==2.1.0
langchain==0.1.0
langchain-openai==0.0.2
langchain-google-genai==0.0.5
openai==1.10.0
google-generativeai==0.3.2
anthropic==0.8.0
pymongo==4.6.1
psycopg2-binary==2.9.9
python-dotenv==1.0.0
httpx==0.26.0
tiktoken==0.5.2
```

#### **2. `app/config.py`**
```python
from pydantic_settings import BaseSettings
from typing import Optional

class Settings(BaseSettings):
    # API Keys
    OPENAI_API_KEY: str
    GEMINI_API_KEY: Optional[str] = None
    ANTHROPIC_API_KEY: Optional[str] = None
    
    # Database
    POSTGRES_URL: str
    MONGODB_URL: str
    MONGODB_DB: str = "universia_chat"
    
    # Service Config
    SERVICE_HOST: str = "0.0.0.0"
    SERVICE_PORT: int = 8000
    API_VERSION: str = "v1"
    
    # AI Config
    DEFAULT_MODEL: str = "gpt-4-turbo-preview"
    DEFAULT_TEMPERATURE: float = 0.7
    MAX_TOKENS: int = 1000
    
    # Security
    SECRET_KEY: str
    ALLOWED_ORIGINS: list = ["http://localhost:3000"]
    
    class Config:
        env_file = ".env"

settings = Settings()
```

#### **3. `app/models/chat_models.py`**
```python
from pydantic import BaseModel, Field
from typing import Optional, List, Dict, Any
from datetime import datetime

class Message(BaseModel):
    role: str = Field(..., description="usuario o asistente")
    content: str
    timestamp: datetime = Field(default_factory=datetime.utcnow)

class ChatRequest(BaseModel):
    session_id: int
    student_id: int
    course_id: int
    lesson_id: Optional[int] = None
    message: str
    context: Optional[Dict[str, Any]] = None

class ChatResponse(BaseModel):
    session_id: int
    message: str
    tokens_used: int
    cost: float
    timestamp: datetime = Field(default_factory=datetime.utcnow)
    metadata: Optional[Dict[str, Any]] = None

class StudentContext(BaseModel):
    """Contexto del estudiante para la IA"""
    student_id: int
    course_id: int
    current_lesson_id: Optional[int]
    completed_lessons: List[int] = []
    progress_percentage: float = 0.0
    learning_objectives: List[str] = []
    key_concepts: List[str] = []
    rubric: Optional[Dict[str, Any]] = None
    tutor_config: Dict[str, Any]
```

#### **4. `app/services/chat_service.py`**
```python
from typing import Dict, Any, List
from langchain_openai import ChatOpenAI
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.schema import HumanMessage, AIMessage, SystemMessage
import psycopg2
from pymongo import MongoClient
from datetime import datetime
from app.config import settings
from app.models.chat_models import ChatRequest, ChatResponse, StudentContext

class ChatService:
    def __init__(self):
        self.pg_conn = psycopg2.connect(settings.POSTGRES_URL)
        self.mongo_client = MongoClient(settings.MONGODB_URL)
        self.mongo_db = self.mongo_client[settings.MONGODB_DB]
        
    def get_student_context(self, student_id: int, course_id: int, lesson_id: Optional[int] = None) -> StudentContext:
        """Obtiene el contexto completo del estudiante desde PostgreSQL"""
        with self.pg_conn.cursor() as cur:
            # Obtener configuraciÃ³n del tutor IA
            cur.execute("""
                SELECT t.modelo_ia, t.prompt_sistema, t.temperatura, t.max_tokens, t.configuracion
                FROM cursos c
                JOIN tutores_ia t ON c.id_tutor = t.id_tutor
                WHERE c.id_curso = %s
            """, (course_id,))
            tutor = cur.fetchone()
            
            # Obtener progreso del estudiante
            cur.execute("""
                SELECT i.progreso_general, 
                       ARRAY_AGG(DISTINCT pl.id_leccion) FILTER (WHERE pl.completado = TRUE) as lecciones_completadas
                FROM inscripciones i
                LEFT JOIN progreso_lecciones pl ON i.id_inscripcion = pl.id_inscripcion
                WHERE i.id_estudiante = %s AND i.id_curso = %s
                GROUP BY i.id_inscripcion, i.progreso_general
            """, (student_id, course_id))
            progress = cur.fetchone()
            
            # Obtener objetivos de la lecciÃ³n actual
            learning_objectives = []
            key_concepts = []
            if lesson_id:
                cur.execute("""
                    SELECT objetivos_aprendizaje, conceptos_clave
                    FROM lecciones
                    WHERE id_leccion = %s
                """, (lesson_id,))
                lesson_data = cur.fetchone()
                if lesson_data:
                    learning_objectives = lesson_data[0] or []
                    key_concepts = lesson_data[1] or []
            
            # Obtener rÃºbrica del mÃ³dulo/curso
            rubric = None
            if lesson_id:
                cur.execute("""
                    SELECT r.criterios, r.escala_evaluacion
                    FROM lecciones l
                    JOIN modulos m ON l.id_modulo = m.id_modulo
                    JOIN rubricas r ON (r.id_modulo = m.id_modulo OR r.id_curso = m.id_curso)
                    WHERE l.id_leccion = %s
                    LIMIT 1
                """, (lesson_id,))
                rubric_data = cur.fetchone()
                if rubric_data:
                    rubric = {
                        "criterios": rubric_data[0],
                        "escala": rubric_data[1]
                    }
            
            return StudentContext(
                student_id=student_id,
                course_id=course_id,
                current_lesson_id=lesson_id,
                completed_lessons=progress[1] if progress and progress[1] else [],
                progress_percentage=float(progress[0]) if progress else 0.0,
                learning_objectives=learning_objectives,
                key_concepts=key_concepts,
                rubric=rubric,
                tutor_config={
                    "model": tutor[0],
                    "system_prompt": tutor[1],
                    "temperature": float(tutor[2]) if tutor[2] else 0.7,
                    "max_tokens": tutor[3] or 1000,
                    "extra": tutor[4] or {}
                }
            )
    
    def build_system_prompt(self, context: StudentContext) -> str:
        """Construye el prompt del sistema basado en el contexto"""
        base_prompt = context.tutor_config.get("system_prompt", "Eres un tutor virtual.")
        
        context_info = f"""
        
CONTEXTO DEL ESTUDIANTE:
- Progreso en el curso: {context.progress_percentage:.1f}%
- Lecciones completadas: {len(context.completed_lessons)}

"""
        
        if context.learning_objectives:
            context_info += f"""
OBJETIVOS DE APRENDIZAJE DE ESTA LECCIÃ“N:
{chr(10).join(f"- {obj}" for obj in context.learning_objectives)}

"""
        
        if context.key_concepts:
            context_info += f"""
CONCEPTOS CLAVE A ENSEÃ‘AR:
{', '.join(context.key_concepts)}

"""
        
        if context.rubric:
            context_info += f"""
RÃšBRICA DE EVALUACIÃ“N:
Usa estos criterios para evaluar la comprensiÃ³n del estudiante:
{context.rubric.get('criterios', {})}

"""
        
        context_info += """
INSTRUCCIONES:
1. Adapta tus explicaciones al nivel de progreso del estudiante
2. Verifica comprensiÃ³n antes de avanzar a nuevos conceptos
3. Usa ejemplos prÃ¡cticos relacionados con los objetivos de la lecciÃ³n
4. Si el estudiante hace preguntas sobre temas no cubiertos aÃºn, guÃ­alo suavemente de vuelta
5. Celebra sus logros y motÃ­valo en sus dificultades
"""
        
        return base_prompt + context_info
    
    def get_chat_history(self, session_id: int, limit: int = 10) -> List[Dict[str, str]]:
        """Obtiene historial de chat desde MongoDB"""
        collection = self.mongo_db.chat_messages
        messages = collection.find(
            {"session_id": session_id}
        ).sort("timestamp", -1).limit(limit)
        
        history = []
        for msg in reversed(list(messages)):
            history.append({
                "role": msg["role"],
                "content": msg["content"]
            })
        return history
    
    async def process_message(self, request: ChatRequest) -> ChatResponse:
        """Procesa el mensaje del estudiante y genera respuesta"""
        # 1. Obtener contexto del estudiante
        context = self.get_student_context(
            request.student_id,
            request.course_id,
            request.lesson_id
        )
        
        # 2. Construir prompt del sistema
        system_prompt = self.build_system_prompt(context)
        
        # 3. Obtener historial de conversaciÃ³n
        history = self.get_chat_history(request.session_id)
        
        # 4. Preparar mensajes para el LLM
        messages = [SystemMessage(content=system_prompt)]
        
        for msg in history:
            if msg["role"] == "usuario":
                messages.append(HumanMessage(content=msg["content"]))
            else:
                messages.append(AIMessage(content=msg["content"]))
        
        messages.append(HumanMessage(content=request.message))
        
        # 5. Llamar al modelo de IA
        model_name = context.tutor_config["model"]
        
        if "gpt" in model_name.lower():
            llm = ChatOpenAI(
                model=model_name,
                temperature=context.tutor_config["temperature"],
                max_tokens=context.tutor_config["max_tokens"],
                api_key=settings.OPENAI_API_KEY
            )
        elif "gemini" in model_name.lower():
            llm = ChatGoogleGenerativeAI(
                model=model_name,
                temperature=context.tutor_config["temperature"],
                max_output_tokens=context.tutor_config["max_tokens"],
                google_api_key=settings.GEMINI_API_KEY
            )
        else:
            raise ValueError(f"Modelo no soportado: {model_name}")
        
        # 6. Generar respuesta
        response = await llm.ainvoke(messages)
        
        # 7. Guardar mensajes en MongoDB
        collection = self.mongo_db.chat_messages
        timestamp = datetime.utcnow()
        
        collection.insert_many([
            {
                "session_id": request.session_id,
                "student_id": request.student_id,
                "course_id": request.course_id,
                "lesson_id": request.lesson_id,
                "role": "usuario",
                "content": request.message,
                "timestamp": timestamp
            },
            {
                "session_id": request.session_id,
                "student_id": request.student_id,
                "course_id": request.course_id,
                "lesson_id": request.lesson_id,
                "role": "asistente",
                "content": response.content,
                "timestamp": timestamp,
                "model": model_name,
                "tokens": getattr(response, 'usage', {}).get('total_tokens', 0)
            }
        ])
        
        # 8. Actualizar mÃ©tricas en PostgreSQL
        tokens_used = getattr(response, 'usage', {}).get('total_tokens', 0)
        cost = self._calculate_cost(model_name, tokens_used)
        
        with self.pg_conn.cursor() as cur:
            cur.execute("""
                UPDATE sesiones_chat_ia
                SET total_mensajes = total_mensajes + 2,
                    tokens_usados = tokens_usados + %s,
                    costo_api = costo_api + %s,
                    activa = TRUE
                WHERE id_sesion = %s
            """, (tokens_used, cost, request.session_id))
            self.pg_conn.commit()
        
        return ChatResponse(
            session_id=request.session_id,
            message=response.content,
            tokens_used=tokens_used,
            cost=cost,
            metadata={
                "model": model_name,
                "context_used": len(history)
            }
        )
    
    def _calculate_cost(self, model: str, tokens: int) -> float:
        """Calcula el costo aproximado de la llamada a la API"""
        costs_per_1k = {
            "gpt-4": 0.03,
            "gpt-4-turbo": 0.01,
            "gpt-3.5-turbo": 0.002,
            "gemini-pro": 0.0005
        }
        
        for key, cost in costs_per_1k.items():
            if key in model.lower():
                return (tokens / 1000) * cost
        
        return 0.0
```

#### **5. `app/routers/chat_router.py`**
```python
from fastapi import APIRouter, HTTPException, Depends
from app.models.chat_models import ChatRequest, ChatResponse
from app.services.chat_service import ChatService

router = APIRouter(prefix="/api/v1/chat", tags=["chat"])

def get_chat_service():
    return ChatService()

@router.post("/completions", response_model=ChatResponse)
async def chat_completion(
    request: ChatRequest,
    service: ChatService = Depends(get_chat_service)
):
    """Procesa un mensaje del estudiante y retorna la respuesta de la IA"""
    try:
        response = await service.process_message(request)
        return response
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/health")
async def health_check():
    """Verifica que el servicio estÃ© funcionando"""
    return {"status": "healthy", "service": "universia-ia"}
```

#### **6. `app/main.py`**
```python
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from app.config import settings
from app.routers import chat_router

app = FastAPI(
    title="UniversIA - Servicio de IA",
    version="1.0.0",
    description="Servicio de chat IA para tutorÃ­as automatizadas"
)

# CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=settings.ALLOWED_ORIGINS,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Routers
app.include_router(chat_router.router)

@app.get("/")
async def root():
    return {
        "message": "UniversIA IA Service",
        "version": "1.0.0",
        "docs": "/docs"
    }

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(
        "app.main:app",
        host=settings.SERVICE_HOST,
        port=settings.SERVICE_PORT,
        reload=True
    )
```

---

## âš›ï¸ API Next.js (Backend)

### **API Route: `/api/chat/send.ts`**

```typescript
// app/api/chat/send/route.ts
import { NextRequest, NextResponse } from 'next/server';
import { headers } from 'next/headers';

const IA_SERVICE_URL = process.env.IA_SERVICE_URL || 'http://localhost:8000';

export async function POST(request: NextRequest) {
  try {
    // 1. Validar autenticaciÃ³n (obtener de headers/cookies)
    const headersList = headers();
    const token = headersList.get('authorization');
    
    if (!token) {
      return NextResponse.json({ error: 'No autorizado' }, { status: 401 });
    }
    
    // 2. Obtener datos del request
    const body = await request.json();
    const { sessionId, studentId, courseId, lessonId, message } = body;
    
    // 3. Validar datos
    if (!sessionId || !studentId || !courseId || !message) {
      return NextResponse.json(
        { error: 'Faltan parÃ¡metros requeridos' },
        { status: 400 }
      );
    }
    
    // 4. Llamar al servicio Python de IA
    const iaResponse = await fetch(`${IA_SERVICE_URL}/api/v1/chat/completions`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        session_id: sessionId,
        student_id: studentId,
        course_id: courseId,
        lesson_id: lessonId,
        message: message,
      }),
    });
    
    if (!iaResponse.ok) {
      const error = await iaResponse.json();
      throw new Error(error.detail || 'Error en servicio de IA');
    }
    
    const iaData = await iaResponse.json();
    
    // 5. Retornar respuesta
    return NextResponse.json({
      success: true,
      data: iaData,
    });
    
  } catch (error: any) {
    console.error('Error en /api/chat/send:', error);
    return NextResponse.json(
      { error: error.message || 'Error interno del servidor' },
      { status: 500 }
    );
  }
}
```

### **API Route: `/api/chat/session.ts`**

```typescript
// app/api/chat/session/route.ts
import { NextRequest, NextResponse } from 'next/server';
import { Pool } from 'pg';

const pool = new Pool({
  connectionString: process.env.DATABASE_URL,
});

export async function POST(request: NextRequest) {
  try {
    const body = await request.json();
    const { studentId, courseId, lessonId } = body;
    
    // Crear nueva sesiÃ³n de chat
    const result = await pool.query(
      `INSERT INTO sesiones_chat_ia (
        id_estudiante, 
        id_curso, 
        id_leccion, 
        id_tutor,
        contexto_sesion
      )
      SELECT $1, $2, $3, c.id_tutor, $4
      FROM cursos c
      WHERE c.id_curso = $2
      RETURNING id_sesion`,
      [
        studentId,
        courseId,
        lessonId,
        JSON.stringify({ created_from: 'web', lesson_id: lessonId }),
      ]
    );
    
    return NextResponse.json({
      success: true,
      sessionId: result.rows[0].id_sesion,
    });
    
  } catch (error: any) {
    console.error('Error creando sesiÃ³n:', error);
    return NextResponse.json(
      { error: error.message },
      { status: 500 }
    );
  }
}

export async function GET(request: NextRequest) {
  try {
    const { searchParams } = new URL(request.url);
    const sessionId = searchParams.get('sessionId');
    
    if (!sessionId) {
      return NextResponse.json(
        { error: 'sessionId requerido' },
        { status: 400 }
      );
    }
    
    // Obtener info de la sesiÃ³n
    const result = await pool.query(
      `SELECT 
        s.*,
        t.nombre as tutor_nombre,
        c.nombre as curso_nombre
      FROM sesiones_chat_ia s
      JOIN tutores_ia t ON s.id_tutor = t.id_tutor
      JOIN cursos c ON s.id_curso = c.id_curso
      WHERE s.id_sesion = $1`,
      [sessionId]
    );
    
    if (result.rows.length === 0) {
      return NextResponse.json(
        { error: 'SesiÃ³n no encontrada' },
        { status: 404 }
      );
    }
    
    return NextResponse.json({
      success: true,
      session: result.rows[0],
    });
    
  } catch (error: any) {
    console.error('Error obteniendo sesiÃ³n:', error);
    return NextResponse.json(
      { error: error.message },
      { status: 500 }
    );
  }
}
```

---

## ğŸ”„ Flujo de Datos Completo

### **Flujo Paso a Paso:**

```
1. ESTUDIANTE ENVÃA MENSAJE
   â†“
2. FRONTEND captura mensaje
   â†’ POST /api/chat/send
   â†“
3. NEXT.JS API ROUTE valida autenticaciÃ³n
   â†’ Obtiene sessionId de PostgreSQL (si no existe, crea uno)
   â†“
4. NEXT.JS llama al SERVICIO PYTHON
   â†’ POST http://localhost:8000/api/v1/chat/completions
   {
     "session_id": 123,
     "student_id": 456,
     "course_id": 1,
     "lesson_id": 5,
     "message": "Â¿QuÃ© es un bucle for?"
   }
   â†“
5. SERVICIO PYTHON (ChatService):
   a) Consulta PostgreSQL:
      - Obtiene progreso del estudiante
      - Obtiene configuraciÃ³n del tutor IA
      - Obtiene objetivos de la lecciÃ³n
      - Obtiene rÃºbrica del mÃ³dulo
   
   b) Consulta MongoDB:
      - Obtiene Ãºltimos 10 mensajes del chat
   
   c) Construye prompt completo:
      ```
      Sistema: Eres Ada, tutora de programaciÃ³n...
               Progreso del estudiante: 35%
               Lecciones completadas: 12
               Objetivos: Comprender estructuras de control...
               Conceptos clave: bucles, iteraciÃ³n, for, while
      
      Usuario: [mensajes anteriores]
      IA: [respuestas anteriores]
      Usuario: Â¿QuÃ© es un bucle for?
      ```
   
   d) Llama a OpenAI/Gemini con el prompt
   
   e) Guarda en MongoDB:
      - Mensaje del usuario
      - Respuesta de la IA
      - Metadata (tokens, modelo, timestamp)
   
   f) Actualiza PostgreSQL:
      - total_mensajes += 2
      - tokens_usados += N
      - costo_api += X
   â†“
6. SERVICIO PYTHON responde a Next.js:
   {
     "session_id": 123,
     "message": "Un bucle for es una estructura...",
     "tokens_used": 150,
     "cost": 0.0045
   }
   â†“
7. NEXT.JS API ROUTE responde al frontend
   â†“
8. FRONTEND muestra respuesta al estudiante
```

---

## ğŸš€ Deployment

### **OpciÃ³n 1: Docker Compose (Desarrollo)**

```yaml
# docker-compose.yml
version: '3.8'

services:
  postgres:
    image: postgres:15
    environment:
      POSTGRES_DB: universia
      POSTGRES_USER: admin
      POSTGRES_PASSWORD: password
    ports:
      - "5432:5432"
    volumes:
      - ./database:/docker-entrypoint-initdb.d
      - postgres_data:/var/lib/postgresql/data
  
  mongodb:
    image: mongo:7
    ports:
      - "27017:27017"
    volumes:
      - mongo_data:/data/db
  
  ia-service:
    build: ./universia-ia-service
    ports:
      - "8000:8000"
    environment:
      POSTGRES_URL: postgresql://admin:password@postgres:5432/universia
      MONGODB_URL: mongodb://mongodb:27017/
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      GEMINI_API_KEY: ${GEMINI_API_KEY}
    depends_on:
      - postgres
      - mongodb
  
  nextjs:
    build: .
    ports:
      - "3000:3000"
    environment:
      DATABASE_URL: postgresql://admin:password@postgres:5432/universia
      IA_SERVICE_URL: http://ia-service:8000
    depends_on:
      - postgres
      - ia-service

volumes:
  postgres_data:
  mongo_data:
```

### **OpciÃ³n 2: ProducciÃ³n (Railway/Vercel + Render)**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FRONTEND + NEXT.JS API                  â”‚
â”‚  Vercel / Railway                        â”‚
â”‚  - Maneja UI                             â”‚
â”‚  - API Routes (/api/chat/*)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼ HTTPS
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SERVICIO IA (Python)                    â”‚
â”‚  Render / Railway / AWS Lambda           â”‚
â”‚  - Puerto 8000                           â”‚
â”‚  - FastAPI + Uvicorn                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼          â–¼          â–¼
   PostgreSQL  MongoDB    OpenAI API
   (Railway)   (Atlas)    (Cloud)
```

---

## ğŸ“ Variables de Entorno

### **Next.js (`.env.local`)**
```env
DATABASE_URL=postgresql://user:pass@host:5432/universia
IA_SERVICE_URL=http://localhost:8000
NEXTAUTH_SECRET=your-secret-key
```

### **Python Service (`.env`)**
```env
OPENAI_API_KEY=sk-...
GEMINI_API_KEY=AIza...
ANTHROPIC_API_KEY=sk-ant-...

POSTGRES_URL=postgresql://user:pass@host:5432/universia
MONGODB_URL=mongodb://host:27017/
MONGODB_DB=universia_chat

SERVICE_HOST=0.0.0.0
SERVICE_PORT=8000

SECRET_KEY=your-secret-key
ALLOWED_ORIGINS=["http://localhost:3000","https://universia.com"]
```

---

## âœ… Checklist de IntegraciÃ³n

- [ ] Base de datos actualizada con rÃºbricas y objetivos
- [ ] Servicio Python creado y funcionando
- [ ] API Routes de Next.js implementadas
- [ ] Frontend actualizado para llamar a las APIs
- [ ] MongoDB configurado para almacenar chats
- [ ] Variables de entorno configuradas
- [ ] Docker Compose para desarrollo local
- [ ] Tests bÃ¡sicos del servicio Python
- [ ] DocumentaciÃ³n de endpoints
- [ ] Deployment en producciÃ³n

---

## ğŸ¯ PrÃ³ximos Pasos

1. **Crear el proyecto Python** con la estructura propuesta
2. **Actualizar el frontend** para consumir las nuevas APIs
3. **Configurar MongoDB** y crear colecciÃ³n de mensajes
4. **Testear localmente** con Docker Compose
5. **Deploy gradual** (primero desarrollo, luego producciÃ³n)
